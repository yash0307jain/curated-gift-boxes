{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d2c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For loading the dataframe\n",
    "import pickle\n",
    "\n",
    "# For loading data and data manipulation\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# For cleaning the text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For converting them into vectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To find the similarity distance between movies\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# For model building libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7862e",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913b3037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preferences</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I‚Äôm more of a tea person üçµ$$$I prefer herbal/d...</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...</td>\n",
       "      <td>hard liquor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...</td>\n",
       "      <td>accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...</td>\n",
       "      <td>liquoraccessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Preferences         Category\n",
       "0  I‚Äôm more of a tea person üçµ$$$I prefer herbal/d...            sweet\n",
       "1  I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...      hard liquor\n",
       "2  I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...        accessory\n",
       "3  I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...  liquoraccessory\n",
       "4  I don‚Äôt drink coffee or tea ü§≠$$$ Chocolates, C...            sweet"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = pickle.load(open(\"eda_data/predict.pkl\", \"rb\"))\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b5de4",
   "metadata": {},
   "source": [
    "# Clean the preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95982183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object of tokenizer and lemmatizer\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fba9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the Preference column\n",
    "def clean_pref(row):\n",
    "    # convert into lower character\n",
    "    row = row.lower()\n",
    "    # split string into words\n",
    "    words = tokenizer.tokenize(row)\n",
    "    # remove stop words and apply lemmatization\n",
    "    words = [lemmatizer.lemmatize(word.strip()) for word in words if word not in stopwords.words('english')]\n",
    "    # convert word into string again and return\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Applying clean preference function to transform the text\n",
    "df_predict['Preference_Clean'] = df_predict['Preferences'].apply(clean_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc34cb",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eabb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_predict['Preference_Clean']\n",
    "y = df_predict['Category']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135b1ca",
   "metadata": {},
   "source": [
    "# Converting feature into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_predict = TfidfVectorizer(max_features=3000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = tfidf_predict.fit_transform(X_train).toarray()\n",
    "X_test_vec = tfidf_predict.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ce98d",
   "metadata": {},
   "source": [
    "# Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d525a",
   "metadata": {},
   "source": [
    "### Increase the model performance:\n",
    "* Initially there were 39 categories, and I am getting the best accuracy of **18 percent**\n",
    "* After that I found out there were some categories which were redundant with a difference of upper and lower character, so after converting all categories to lower character, and I am getting the best accuracy of around **20 percent**\n",
    "* Then to improve further I remove the categories that has less than 50 records, and I am getting the best accuracy of **23 percent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b021f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
    "knc = KNeighborsClassifier(n_neighbors=97)\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503db8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_perf = []\n",
    "classifiers = [svc, knc, bnb, mnb, dtc, lrc, rfc, abc, bc, etc, gbdt]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train_vec, y_train)\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_perf.append({'Model': classifier, 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c29f1",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe7071",
   "metadata": {},
   "source": [
    "# Creating recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommend = pickle.load(open(\"eda_data/recommendation.pkl\", 'rb'))\n",
    "df_recommend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4ed09",
   "metadata": {},
   "source": [
    "### Converting tags column into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_recommend = TfidfVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5822c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_vec = tfidf_recommend.fit_transform(df_recommend['Tag']).toarray()\n",
    "recommend_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85742f35",
   "metadata": {},
   "source": [
    "### Calculate the cosine distance between the vectors, and the values of matrix represent the percentage of similarity between tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df935af",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(recommend_vec)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbbeb3",
   "metadata": {},
   "source": [
    "### Recommender function that will give the recommended movies closest to the given one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc61551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(product):\n",
    "    product_index = df_recommend[df_recommend['ProductName'] == product].index[0]\n",
    "    similarity_percentage = similarity[product_index]\n",
    "    recommended_product = sorted(list(enumerate(similarity_percentage)), reverse=True, key=lambda x:x[1])[1:6]\n",
    "    \n",
    "    products = []\n",
    "    for index in recommended_product:\n",
    "        products.append(df_recommend.iloc[index[0]]['ProductName'])\n",
    "        \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741afbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender(\"Pecan Shortbread cookies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e6dcc",
   "metadata": {},
   "source": [
    "# Pipeline that recommends products on the basis of preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6caad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(pref):\n",
    "    # creating a dataframe\n",
    "    df = pd.DataFrame({\"Preference\": [pref]})\n",
    "    \n",
    "    # cleaning the preference\n",
    "    df['Preference_Clean'] = df['Preference'].apply(clean_pref)\n",
    "    \n",
    "    # transform the preference into vectors\n",
    "    df_vec = tfidf_predict.transform(df['Preference_Clean']).toarray()\n",
    "    \n",
    "    # predict the category\n",
    "    pred = svc.predict(df_vec)[0]\n",
    "    print(\"Predicted Tag:\", pred)\n",
    "    \n",
    "    # predict probability\n",
    "    pred_prob = svc.predict_proba(df_vec)[0]\n",
    "    \n",
    "    # dictionary of category with its probability\n",
    "    category_prob = {}\n",
    "    for i in range(len(pred_prob)):\n",
    "        category_prob[svc.classes_[i]] = pred_prob[i]\n",
    "    \n",
    "    # sort the dictionary to get the max two\n",
    "    category_prob_sort = dict(sorted(category_prob.items(), key=lambda item: item[1], reverse=True))\n",
    "    pred_two = list(category_prob_sort.keys())[:2]\n",
    "    print(\"\\nProduct tag sorted:\", category_prob_sort)\n",
    "    \n",
    "    # fecthing all the products which has category as product\n",
    "    df_product = df_recommend[df_recommend['ProductTag'].apply(lambda product_tag: pred in product_tag.lower())]\n",
    "    df_product = df_product[['ProductId', 'ProductName', 'Cost', 'Price']]\n",
    "    \n",
    "    product_name = df_product.iloc[0]['ProductName']\n",
    "    print(\"\\nProduct Name:\", product_name)\n",
    "    \n",
    "    # recommend product similar to product name\n",
    "    print(\"\\nRecommended products:\")\n",
    "    print(\"--------------------------\")\n",
    "    recommends = recommender(product_name)\n",
    "    for recommend in recommends:\n",
    "        print(recommend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953651",
   "metadata": {},
   "source": [
    "# Check with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sample = pd.read_csv(\"data/test_input.csv\")\n",
    "df_test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sample = df_test_sample[['OrderPrice', 'Preferences']]\n",
    "df_test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ad8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = df_test_sample['Preferences'][8]\n",
    "test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0920584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
